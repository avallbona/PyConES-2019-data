{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "pycones_surprise_algorithms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rVN8MKSAOIr",
        "colab_type": "code",
        "pycharm": {
          "is_executing": false
        },
        "colab": {}
      },
      "source": [
        "!pip install numpy pandas plotly surprise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB1QoqiXALDT",
        "colab_type": "text"
      },
      "source": [
        "# Filtrado Colaborativo\n",
        "- Empareja usuarios con gente que tiene gustos similares\n",
        "- Usuarios que tienen gustos similares se colocan en el mismo grupo/conjunto algorítmicamente hablando, y las recomendaciones se sugieren basadas en los gustos/intereses de estos usuarios en cada grupo particular (cluster)\n",
        "- Presentaremos tres técnicas de **Filtrado Colaborativo**:  Filtrado Colaborativo usuario-usuario, Filtrado Colaborativo elemento-elemento y Factorización de Matrices\n",
        "\n",
        "Para este fin, haremos uso de la librería [Surprise](http://surpriselib.com) de Python, una librería Python de código abierto fácil de usar para construir y analizar Sistemas de Recomendación, creada por *Nicolas Hug*.\n",
        "Surprise proporciona la mayoría de los algoritmos fundamentales para crear Sistemas de Recomendación basados en Filtrado Colaborativo.\n",
        "El nombre **SurPRISE** proviene de  **Simple Python RecommendatIon System Engine**.\n",
        "\n",
        "Algunas de las características proporcionadas por Surprise son:\n",
        "* Da al usuario un perfecto control sobre sus experimentos\n",
        "* Documentación extensa y clara ofreciendo detalles precisos de cada algoritmo\n",
        "* Una variedad de algoritmos de predicción listos para ser usados, como algoritmos baseline, métodos de vecindad (K-Neighbours), métodos basados en factorización de matrices (SVD, PMF, SVD++, NMF) y muchos más\n",
        "* Diferentes medidas de similitud como Coseno, MSD (Mininum Square Difference) y Pearson entre otras\n",
        "* Herramientas para evaluar, analizar y comparar el rendimiento de los algoritmos. Los procedimientos de validación cruzada pueden ser ejecutados muy fácilmente utilizando potentes iteradores de CV (inspirados en los que se pueden encontrar en scikit-learn), así como una búsqueda exhaustiva sobre un conjunto de parámetros\n",
        "* Facilita la implementación de nuevas ideas de algoritmos de recomendación\n",
        "* Alivia la tediosa tarea del manejo del conjunto de datos. Los usuarios pueden usar conjuntos de datos integrados (Movielens, Jester) y sus propios conjuntos de datos personalizados\n",
        "\n",
        "En los siguientes ejemplos, utilizaremos el conjunto de datos *Movielens* para mostrar cómo construir, usar y evaluar algunos de los algoritmos de Filtrado Colaborativo. El conjunto de datos Movielens viene ya integrado en Surprise, permitiendo descargar diferentes conjuntos de datos dependiendo del tamaño deseado.\n",
        "Movielens 100k (ml-100k), Movielens 1M (ml-1m) y Jester (jester) son los conjuntos de datos que vienen incorporados listos para usar en Surprise, de forma que no es necesario recoger, procesar y preparar datos de usuarios y elementos para comenzar a utilizar los algoritmos disponibles en Surprise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "mHfxOC7jALDY",
        "colab_type": "text"
      },
      "source": [
        "# Análisis Exploratorio de Datos (EDA - Exploratory Data Analysis)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "9fsOgLw6ALDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from surprise import Dataset, get_dataset_dir\n",
        "import pandas as pd\n",
        "#Load dataset using in-built Surprise Dataset class\n",
        "Dataset.load_builtin('ml-100k')\n",
        "user = pd.read_csv(get_dataset_dir()+ '/ml-100k/ml-100k/u.user', sep='|', error_bad_lines=False, encoding=\"latin-1\")\n",
        "user.columns = ['userID', 'age', 'gender', 'occupation', 'zipCode']\n",
        "rating = pd.read_csv(get_dataset_dir() + '/ml-100k/ml-100k/u.data', sep='\\t', error_bad_lines=False, encoding=\"latin-1\")\n",
        "rating.columns = ['userID', 'movieID', 'movieRating', 'timestamp']\n",
        "df = pd.merge(user, rating, on='userID', how='inner')\n",
        "df.drop(['age', 'gender', 'zipCode', 'timestamp'], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "movsrbYzALDk",
        "colab_type": "text"
      },
      "source": [
        "## Distribución de valoraciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "jHWqsyF_ALDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from plotly.offline import init_notebook_mode, iplot\n",
        "import plotly.graph_objs as go\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "data = df['movieRating'].value_counts().sort_index(ascending=False)\n",
        "print(data)\n",
        "print(data.index)\n",
        "print(data.values)\n",
        "print(df.shape[0])\n",
        "\n",
        "# Create the trace data\n",
        "trace = go.Bar(x = data.index,\n",
        "               text = ['{:.1f} %'.format(val) for val in (data.values / df.shape[0] * 100)],\n",
        "               textposition = 'auto',\n",
        "               textfont = dict(color = '#000000'),\n",
        "               y = data.values,\n",
        "               )\n",
        "# Create figure layout\n",
        "layout = dict(title = 'Distribución de {} valoraciones'.format(df.shape[0]),\n",
        "              xaxis = dict(title = 'Valoración'),\n",
        "              yaxis = dict(title = 'Recuento'))\n",
        "\n",
        "# Create plot with data and layout\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "#iplot(fig)\n",
        "fig.show(renderer='colab')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "RqhoyLnDALDt",
        "colab_type": "text"
      },
      "source": [
        "## Distribución de valoraciones por película\n",
        "## Número de valoraciones por película"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "9ybOJ42TALDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Movies with rating bigger than 50, will be set to 50\n",
        "data = df.groupby('movieID')['movieRating'].count().clip(upper=50)\n",
        "\n",
        "# Create the trace data\n",
        "trace = go.Histogram(x = data.values,\n",
        "                     name = 'Valoraciones',\n",
        "                     xbins = dict(start = 0,\n",
        "                                  end = 51,\n",
        "                                  size = 2))\n",
        "# Create figure layout\n",
        "layout = go.Layout(title = 'Distribución de número de valoraciones por película (Límite de 50)',\n",
        "                   xaxis = dict(title = 'Número de valoraciones por película'),\n",
        "                   yaxis = dict(title = 'Recuento'),\n",
        "                   bargap = 0.2)\n",
        "\n",
        "# Create plot with data and layout\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "#iplot(fig)\n",
        "fig.show(renderer='colab')\n",
        "\n",
        "\n",
        "print(\"Recuento Película-Puntuación (Top 10)\")\n",
        "movie_ratings_count = df.groupby('movieID')['movieRating'].count().reset_index().sort_values('movieRating', ascending=False)[:10]\n",
        "print(movie_ratings_count)\n",
        "\n",
        "print(\"Número de películas: %s\" % df.groupby('movieID')['movieRating'].count().shape[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "JgO6OhWZALD1",
        "colab_type": "text"
      },
      "source": [
        "## Distribución de valoraciones por usuario"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n",
          "is_executing": false
        },
        "id": "BHFVnTdoALD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of ratings per user\n",
        "#Users which gave more than 50 ratings, will be cut off to 50\n",
        "data = df.groupby('userID')['movieRating'].count().clip(upper=50)\n",
        "\n",
        "# Create the trace data\n",
        "trace = go.Histogram(x = data.values,\n",
        "                     name = 'Valoraciones',\n",
        "                     xbins = dict(start = 0,\n",
        "                                  end = 51,\n",
        "                                  size = 2))\n",
        "# Create figure layout\n",
        "layout = go.Layout(title = 'Distribución de número de valoraciones por usuario (Límite de 50)',\n",
        "                   xaxis = dict(title = 'Valoraciones por usuario'),\n",
        "                   yaxis = dict(title = 'Recuento'),\n",
        "                   bargap = 0.2)\n",
        "\n",
        "# Create plot with data and layout\n",
        "fig = go.Figure(data=[trace], layout=layout)\n",
        "#iplot(fig)\n",
        "fig.show(renderer='colab')\n",
        "\n",
        "\n",
        "print(\"Recuento Usuario-Puntuación (Top 10)\")\n",
        "user_ratings_count = df.groupby('userID')['movieRating'].count().reset_index().sort_values('movieRating', ascending=False)[:10]\n",
        "print(user_ratings_count)\n",
        "\n",
        "print(\"Número de usuarios: %s\" % df.groupby('userID')['movieRating'].count().shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "j2daWng_ALD8",
        "colab_type": "text"
      },
      "source": [
        "# Filtrado Colaborativo Usuario-Usuario (K-Nearest Neighbours Clustering)\n",
        "- Para predecir la valoración de un usuario **u** sobre un elemento **i** (no valorado por el usuario u), usaremos la media ponderada (ajustada por la media de las valoraciones de cada usuario)\n",
        "$$ p_{u,i} = \\bar{r_u} + \\frac{\\sum_{v\\in{N_i^{k}(u)}} sim(u,v) \\cdot  (r_{vi} - \\bar{r_v})}{\\sum_{v\\in{N_i^{k}(u)}} sim(u,v)}$$\n",
        "- La salida es la predicción de la valoración del usuario u sobre el elemento i\n",
        "- Usaremos la **medida de similitud entre el usuario u y el usuario v**, donde cada usuario v está en el mismo grupo (cluster) que el usuario u, calculado por el algoritmo\n",
        "    - Como medida de similitud utilizaremos **Pearson baseline** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false
        },
        "id": "FERaQ4N4ALD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import (absolute_import, division, print_function, unicode_literals)  # Compatibility imports\n",
        "import io\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from surprise import Dataset, get_dataset_dir\n",
        "from surprise import KNNWithMeans\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9lswydBTALEF",
        "colab_type": "text"
      },
      "source": [
        "Cargamos el conjunto de datos Movielens 100k (ml-100k) -> El formato es `UserID   MovieID Rating  Timestamp`\n",
        "\n",
        "A continuación, dividimos el conjunto de datos en dos subconjuntos: conjunto de entrenamiento (training set) y conjunto de prueba (test set). Indicaremos que queremos utilizar el 15% de los datos para el conjunto de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "HL3tozXTALEH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = Dataset.load_builtin('ml-100k')\n",
        "training_set, test_set = train_test_split(data, test_size=.15)\n",
        "data.raw_ratings\n",
        "def read_item_names():\n",
        "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
        "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
        "    \"\"\"\n",
        "\n",
        "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
        "    rid_to_name = {}\n",
        "    name_to_rid = {}\n",
        "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
        "        for line in f:\n",
        "            line = line.split('|')\n",
        "            rid_to_name[line[0]] = line[1]\n",
        "            name_to_rid[line[1]] = line[0]\n",
        "\n",
        "    return rid_to_name, name_to_rid\n",
        "\n",
        "# Read the mappings raw id <-> movie name\n",
        "rid_to_name, name_to_rid = read_item_names()\n",
        "\n",
        "# Retrieve inner id of the movie Toy Story\n",
        "#toy_story_raw_id = name_to_rid['Toy Story (1995)']\n",
        "#toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "q7q0KC1TALEL",
        "colab_type": "text"
      },
      "source": [
        "Creamos una instancia del [algoritmo KNNWithMeans](https://surprise.readthedocs.io/en/stable/knn_inspired.html#surprise.prediction_algorithms.knns.KNNWithMeans) para calcular las predicciones basadas en los K-Vecinos más cercanos a un usuario dado.\n",
        "El parámetro *sim_options* permite configurar la medida de similitud a utilizar y si el algoritmo debería utilizar un enfoque basado en *usuario* (calcula usuarios cercanos) o basado en *elemento* (calcula elementos cercanos). Se utiliza verdadero o falso para cambiar entre el enfoque de filtrado colaborativo basado en usuario y el basado en elemento\n",
        "Como medida de similitud, vamos a emplear [Pearson Baseline](https://surprise.readthedocs.io/en/stable/similarities.html#surprise.similarities.pearson_baseline)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% \n"
        },
        "id": "K1dmsu_jALEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_based_algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': True})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "6EumPpwMALES",
        "colab_type": "text"
      },
      "source": [
        "Una vez que hemos creado el algoritmo, necesitamos entrenarlo utilizando el conjunto de datos de entrenamiento.\n",
        "Para ello, se utiliza el método *fit* de la instancia del algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "qn05_cqbALET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_based_algo.fit(training_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "IkQHv4jIALEa",
        "colab_type": "text"
      },
      "source": [
        "Después de que el algoritmo haya sido entrenado (es decir, ha calculado las similitudes entre los usuarios y ha formado los grupos/clusters de usuarios), podemos pedirle por sugerencias/predicciones específicas.\n",
        "Vamos a intentar predecir la valoración del elemento 302 (L.A. Confidential 1997) para el usuario 196 ( sabemos que el usuario valoraría esa película con un 4)\n",
        "Sólo necesitamos llamar al método *predict* de la instancia del algoritmo, pasándole como parametros el usuario y el elementopara el cual queremos obtener la predicción calculada. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "aFg_o93ZALEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "user_id = str(196)\n",
        "item_id = str(302)\n",
        "print(\"Obteniendo la predicción del usuario 196 para la película\", rid_to_name[item_id])\n",
        "\n",
        "pred = user_based_algo.predict(user_id, item_id, r_ui=4, verbose=True)\n",
        "\n",
        "print(\"La predicción es {}\".format(pred.est))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "U1ocwlWlALEn",
        "colab_type": "text"
      },
      "source": [
        "Esto es sólo un ejemplo de como obtener una única predicción calculada para un usuario dado.\n",
        "Si quisieramos obtener la lista de elementos recomendados para cierto usuario (elementos que no han sido valorados aún por el usuario),\n",
        "Surprise no proporciona ninguna caracerística lista para usar para alcanzar este objetivo, pero podemos lograrlo utilizando características ya existentes y proporcionadas por Surprise. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "tAbitEvXALEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict ratings for all pairs (u, i) that are NOT in the training set.\n",
        "number_of_predictions = 10\n",
        "no_ratings_set = training_set.build_anti_testset()\n",
        "predictions = user_based_algo.test(no_ratings_set)\n",
        "# First map the predictions to each user.\n",
        "top_n = defaultdict(list)\n",
        "for uid, iid, true_r, est, _ in predictions:\n",
        "    top_n[uid].append((iid, est))\n",
        "\n",
        "# Then sort the predictions for each user and retrieve the k highest ones.\n",
        "for uid, user_ratings in top_n.items():\n",
        "    user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "    top_n[uid] = user_ratings[:number_of_predictions]\n",
        "\n",
        "# Print recommended items for user 196\n",
        "for (iid, rating) in top_n[user_id]:\n",
        "    print(\"Película: {} - Valoración: {}\".format(rid_to_name[iid], rating))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xzzfps_uALEt",
        "colab_type": "text"
      },
      "source": [
        "De manera similar, también podemos evaluar cuán buenas son las predicciones calculadas.\n",
        "Podemos emplear el modelo entrenado contra el conjunto de pruebas, utilizando el método *test*.\n",
        "Después, podemos utilizar la raíz del error cuadrático medio - RMSE (Root Mean Square Error) - para evaluar cómo de bueno/malo es el modelo generado.\n",
        "Surprise proporciona esa métrica de evaluación en su paquete **accuracy** (paquete de precisión) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "KQTxRzNBALEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = user_based_algo.test(test_set)\n",
        "print(\"Modelo basado en usuario : Conjunto de prueba\")\n",
        "accuracy.rmse(test_pred, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "fEICp4RfALEz",
        "colab_type": "text"
      },
      "source": [
        "Únicamente utilizando el valor anterior de RMSE, normalmente no podremos saber/determinar si el modelo es bueno o malo por sí mismo.\n",
        "Siendo ese el caso, una manera posible de saber como se comporta el modelo es mediante el cálculo de RMSE sobre el conjunto de entrenamiento y comparar dicho valor con el valor RMSE obtenido para el conjunto de prueba. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "tuO20Jr4ALE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Modelo basado en usuario : Conjunto de entrenamiento\")\n",
        "train_pred = user_based_algo.test(training_set.build_testset())\n",
        "accuracy.rmse(train_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "9qfe5TJ6ALE4",
        "colab_type": "text"
      },
      "source": [
        "Por regla general, si ambos valores de RMSE son similares, podríamos decir que nuestro modelo ha aprendido a predecir buenos valores y, por lo tanto, proporcionar buenas sugerencias.\n",
        "\n",
        "Por otra parte, si el valor de RMSE del conjunto de prueba es mucho mayor que el que el valor RMSE del conjunto de entrenamiento probablemente el modelo erróneamente se ha sobreajustado a los datos (overfitting),\n",
        "lo cual significa que hemos creado un modelo que cumple bien con los datos de ejemplo/prueba pero que posee escaso valor predictivo cuando se pone a prueba fuera de ese conjunto de prueba.\n",
        "Por el contrario, si el valor de RMSE del conjunto de prueba es mucho más bajo, entonces el modelo subre de subajuste de datos (underfitting).\n",
        "\n",
        "Sólo porque los valores de RMSE sean similares y nuestro modelo no está sobreajustando/subajustando los datos no quiere decir que hayamos construído un buen modelo. Sólamente indica que hemos construído un modelo que funciona consistentemente bien sobre los nuevos datos proporcionados.\n",
        "Lo mejor que podemos hacer aquí es usar diferentes conjuntos de prueba y conjuntos de validación cruzada o cross-validation (datos que no están incluídos en los conjuntos de entrenamiento y prueba) para calcular más valores para ser comparados y utilizar métricas diferentes (y comparar dichos valores por ellos mismos).\n",
        "\n",
        "De todas maneras, en esta situación, necesitamos desarrollar nuestra propia intuición aplicando esto y aprendiendo de muchos casos de uso diferentes.\n",
        "\n",
        "Además, necesitamos ser conscientes que el valor de RMSE es dependiente de la escala, es decir, dependiente de nuestra variable dependiente (la escala de valoraciones en este caso).\n",
        "Por esta razón, muchas soluciones utilizan el valor normalizado RMSE (NRMSE) utilizando los valores máximos y minimos o la media de los valores para hacerlos independiente de la escala y de alguna manera comparable entre modelos.\n",
        "\n",
        "\n",
        "# Filtrado Colaborativo Elemento-Elemento\n",
        "- Este método de Filtrado Colaborativo es similar al anterior con la diferencia de que la similitud se calcula entre elementos en vez de entre usuarios.\n",
        "\n",
        "$$ p_{u,i} = \\bar{r_i} + \\frac{\\sum_{j\\in{N_u^{k}(i)}} sim(i,j) \\cdot  (r_{uj} - \\bar{r_j})}{\\sum_{v\\in{N_u^{k}(i)}} sim(i,j)}$$\n",
        "\n",
        "- Observar que en la ecuación, **la similitud es entre el elemento i y j**, en lugar de entre el usuario u y v as como fue el caso en el [Filtrado Colaborativo Usuario-Usuario](#Filtrado-Colaborativo-Usuario-Usuario-(K-Nearest-Neighbours-Clustering))\n",
        "\n",
        "- Algunas ventajas de los filtrados basados en elementos sobre los filtrados basados en usuarios son:\n",
        "    - Escalan mejor. La razón es que el filtrado basado en usuario no escala muy bien porque los intereses (gustos) del usuario pueden cambiar frecuentemente dependiendo de, por ejemplo, la época del año como las campañas del Black Friday, Navidad, etc donde los usuarios pueden cambiar sus intereses buscando cosas muy distintas comparado con lo que suelen estar interesados. Debido a esto, los motores de recomendación necesitan ser re-entrenados con bastante frecuencia.\n",
        "    - Más baratos computacionalmente hablando. En algunas situaciones, hay muchísimos más usuarios que elementos. En este caso, el filtrado colaborativo basado en elementos es más apropiado.\n",
        "    \n",
        "- Uno de los filtrados colaborativos basados en elementos más conocido es el [Motor de Recomendación de Amazon](#https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "8L4LBD-DALE7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import (absolute_import, division, print_function,\n",
        "                        unicode_literals)\n",
        "\n",
        "from surprise import KNNWithMeans\n",
        "from surprise import Dataset\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Built-in movielens-100k dataset.  UserID   MovieID Rating  Timestamp\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "training_set, test_set = train_test_split(data, test_size=.15)\n",
        "\n",
        "# We want to run the algorithm based on items, se we configure the user_based option of the algorithm to false\n",
        "item_based_algo = KNNWithMeans(k=50, sim_options={'name': 'pearson_baseline', 'user_based': False})\n",
        "item_based_algo.fit(training_set)\n",
        "\n",
        "# Test the trained model against the test_set\n",
        "test_pred = item_based_algo.test(test_set)\n",
        "\n",
        "# Calculate RMSE of test predictions\n",
        "print(\"Modelo basado en elemento : Conjunto de prueba\")\n",
        "accuracy.rmse(test_pred, verbose=True)\n",
        "\n",
        "# Calculate RMSE of the training predictions\n",
        "print(\"Modelo basado en elemento : Conjunto de entrenamiento\")\n",
        "training_pred = item_based_algo.test(training_set.build_testset())\n",
        "accuracy.rmse(training_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uVV3OP9SALE-",
        "colab_type": "text"
      },
      "source": [
        "## Factorización de Matrices\n",
        "Los métodos basados en usuarios y elementos son fáciles, intuitivos y comprensibles, pero en muchos casos no funcionan tan bien como podríamos esperar.\n",
        "\n",
        "Otro método dentro de los métodos de Filtrado Colaborativo es la Factorización de Matrices (Matrix Factorization).\n",
        "Las técnicas de factorización de matrices son generalmente más efectivas que las basadas en usuarios/elementos ya que nos permiten averiguar características latentes subyacentes a las interacciones entre usuarios y elementos, las cuales son por lo general, desconocidas para nosotros.\n",
        "\n",
        "Una de las técnicas más populares de Factorización de Matrices es la *Descomposición de Valores Singulares*, **Singular Value Decomposition (SVD)**.\n",
        "La técnica se hizo más popular después de la competición que propuse [Netflix Prize competition](https://en.wikipedia.org/wiki/Netflix_Prize). La entrada ganadora del famoso [Premio Netflix](https://www.netflixprize.com/) tenía una serie de modelos SVD, incluyendo SVD++ mezclado con máquinas Boltzmann restringidas (Restricted Boltzmann Machines).\n",
        "Al utilizar estos métodos, el equipo ganador logró un aumento del 10 por ciento en precisión sobre el algoritmo existente de Netflix, ganando el premio de 1 millón de dólares.\n",
        "\n",
        "El artículo [Netflix Prize and SVD](http://buzzard.ups.edu/courses/2014spring/420projects/math420-UPS-spring-2014-gower-netflix-SVD.pdf) diseñado para personas con un conociiento básico de álgebra lineal y descomposición, trata de explicar el funcionamiento de estos algoritmos de SVD de una manera que la mayoría de personas puedan entender.\n",
        "\n",
        "Aunque esta técnica es mucho más compleja y difícil de entender, de nuevo, **Surprise** ha hecho todo el trabajo duro, de forma que nosotros podemos aplicar esta técnica fácilmente de una manera similar a la que ya hemos hecho para los algoritmos de filtrado colaborativo basado en usuarios y elementos.\n",
        " \n",
        "En el siguiente ejemplo, se muestra como aplicar Factorización de Matrices por medio de SVD, haciendo uso del descenso de gradiente para minimizar el error cuadrático entre la valoración predicha y la real, obteniendo mejores modelos la mayoría de las veces.\n",
        "Visitando la [documentación](http://surprise.readthedocs.io/en/stable/matrix_factorization.html) de Surprise, podemos aprender más acerca de las técnicas de Factorización de Matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "flGjoOHnALE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import (absolute_import, division, print_function,\n",
        "                        unicode_literals)\n",
        "\n",
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Built-in movielens-100K dataset\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "training_set, test_set = train_test_split(data, test_size=.15)\n",
        "\n",
        "# Singular Value Decomposition specific configuration\n",
        "svd_algo = SVD(n_factors=160, n_epochs=100, lr_all=0.005, reg_all=0.1)\n",
        "svd_algo.fit(training_set)\n",
        "\n",
        "# Calculate predictions\n",
        "test_pred = svd_algo.test(test_set)\n",
        "\n",
        "# Calculate RMSE of test predictions\n",
        "print(\"SVD : Conjunto de prueba\")\n",
        "accuracy.rmse(test_pred, verbose=True)\n",
        "\n",
        "# Calculate RMSE of training predictions\n",
        "print(\"SVD : Conjunto de entrenamiento\")\n",
        "training_pred = svd_algo.test(training_set.build_testset())\n",
        "accuracy.rmse(training_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b1GICBhQALFE",
        "colab_type": "text"
      },
      "source": [
        "En el ejemplo anterior, hemos configurado el algoritmo SVD con algunos parámetros, porque ya sabíamos por experimentación los mejores valores para ello.\n",
        "Generalmente, la combinación de parámetros adecuada para nuestro caso de uso es desconocida y tenemos que hacer experimentaciones antes de decidir cuáles son los mejores valores de parámetros para el algoritmo.\n",
        "\n",
        "Afortunadamente, **Surprise** contiene un conjunto de funciones de ayuda y procedimientos de Validación Cruzada que nos pueden ayudar a descubrir la mejor configuración para nuestros algoritmos.\n",
        "\n",
        "La función **cross_validate()** y los iteradores de Validación Cruzada, proporcionan métricas de precisión sobre un procedimiento de validación cruzada para un conjunto de parámetros dado. \n",
        "Pero si lo que nosotros queremos es saber la combinación de parámetros que genera mejores resultados, la clase **GridSearchCV** es muy útil para este propósito. Dado un diccionario de parámetros, esta clase exhaustivamente prueba todas las combinaciones de parámetros e informa de los mejores parámetros para cualquier medida de precisión (ponderada sobre diferentes divisiones). **GridSearchCV** utiliza el iterador de Validación Cruzada [KFold](https://surprise.readthedocs.io/en/stable/model_selection.html#surprise.model_selection.split.KFold) internamente.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "kJh-aQ9qALFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from surprise import SVD\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import GridSearchCV, cross_validate\n",
        "\n",
        "# Built-in movielens-100K dataset\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
        "              'reg_all': [0.4, 0.6]}\n",
        "\n",
        "# GridSearchCV using RMSE and MAE\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "\n",
        "# Fit method to calculate the best configuration\n",
        "gs.fit(data)\n",
        "\n",
        "# Best RMSE score\n",
        "print(\"Mejor valor de RMSE:\", gs.best_score['rmse'])\n",
        "\n",
        "# Get the best combination of parameters that gave the best RMSE score\n",
        "print(\"Mejor combinación de parametros:\", gs.best_params['rmse'])\n",
        "\n",
        "# Now, we can obtain an algorithm instance that yields the best RMSE\n",
        "best_svd_algo = gs.best_estimator['rmse']\n",
        "\n",
        "# Let's run the cross_validate function against the best SVD algorithm obtained\n",
        "print(\"\\nValidación Cruzada del algoritmo SVD sobre 5 divisiones\")\n",
        "cross_validate(best_svd_algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# We can use the best SVD  algorithm to learn and create a model using fit\n",
        "#best_svd_algo.fit(data.build_full_trainset())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}